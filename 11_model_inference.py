#!/usr/bin/env python3
"""
æ¨¡å‹æ¨ç†è„šæœ¬
ç”¨äºåŠ è½½å·²è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶å¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹

è‡ªåŠ¨åœ¨ ./models/{model_name}/ è·¯å¾„ä¸‹æ‰¾åˆ°æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶ã€‚
åŠ è½½æ‰€æœ‰äº¤å‰éªŒè¯æŠ˜å æ¨¡å‹ï¼Œä½¿ç”¨æŠ•ç¥¨è¿›è¡Œæœ€ç»ˆé¢„æµ‹ã€‚
æ”¯æŒåˆ†ç±»å’Œæ¦‚ç‡é¢„æµ‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    python 11_model_inference.py --model xgboost --data data/data_out.csv --show_summary
"""

import sys
import os

# æ·»åŠ mlç›®å½•åˆ°è·¯å¾„
sys.path.append('ml')

from model_inference import ModelInference
from ml_config import MLConfig
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def main():
    """ä¸»å‡½æ•° - æ¨¡å‹æ¨ç†æ¥å£"""
    import argparse

    parser = argparse.ArgumentParser(
        description='æ¨¡å‹æ¨ç†å·¥å…· - åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œé¢„æµ‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä½¿ç”¨XGBoostæ¨¡å‹è¿›è¡Œæ¨ç†
  python 11_model_inference.py --model xgboost --data data/data_out.csv --output xgboost_predictions.csv

  # ä½¿ç”¨éšæœºæ£®æ—æ¨¡å‹
  python 11_model_inference.py --model random_forest --data data/data_out.csv

  # æŒ‡å®šç‰¹å¾åˆ—
  python 11_model_inference.py --model xgboost --data data/data_out.csv --features COR_BPFO COR_BPFI COR_BSF

  # ä½¿ç”¨æŒ‡å®šæ•°é‡çš„æ¨¡å‹ï¼ˆæ¯”å¦‚åªç”¨3æŠ˜äº¤å‰éªŒè¯ä¸­çš„æ¨¡å‹ï¼‰
  python 11_model_inference.py --model xgboost --data data/data_out.csv --num_folds 3

  # ä¸è®¡ç®—å‡†ç¡®ç‡ï¼ˆä»…é¢„æµ‹ï¼‰
  python 11_model_inference.py --model xgboost --data data/data_out.csv --no_evaluate
        """
    )

    parser.add_argument('--model', type=str, required=True,
                       choices=['xgboost', 'random_forest', 'knn', 'svm', 'decision_tree',
                               'adaboost', 'extra_trees', 'gradient_boosting', 'bagging_ensemble'],
                       help='è¦ä½¿ç”¨çš„æ¨¡å‹ç±»å‹')

    parser.add_argument('--data', type=str, default='data/data_out.csv',
                       help='è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: data/data_out.csv)')

    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: {model}_predictions.csv)')

    parser.add_argument('--features', type=str, nargs='+', default=None,
                       help='è¦ä½¿ç”¨çš„ç‰¹å¾åˆ—å (å¦‚æœä¸æŒ‡å®šï¼Œå°†ä½¿ç”¨æ‰€æœ‰åˆ—)')

    parser.add_argument('--voting', type=str, default='majority',
                       choices=['majority', 'average'],
                       help='é›†æˆæ¨¡å‹çš„æŠ•ç¥¨ç­–ç•¥ (é»˜è®¤: majority)')

    parser.add_argument('--num_folds', type=int, default=None,
                       help='è¦ä½¿ç”¨çš„æ¨¡å‹æŠ˜æ•° (é»˜è®¤: ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹)')

    parser.add_argument('--show_summary', action='store_true',
                       help='æ˜¾ç¤ºé¢„æµ‹ç»“æœæ±‡æ€»')

    parser.add_argument('--evaluate', action='store_true', default=True,
                       help='è®¡ç®—å¹¶æ˜¾ç¤ºé¢„æµ‹å‡†ç¡®ç‡ (é»˜è®¤: True)')

    parser.add_argument('--no_evaluate', dest='evaluate', action='store_false',
                       help='ä¸è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡')

    args = parser.parse_args()

    # è®¾ç½®é»˜è®¤è¾“å‡ºæ–‡ä»¶å
    if args.output is None:
        args.output = f"{args.model}_predictions.csv"

    logger.info("="*60)
    logger.info("æ¨¡å‹æ¨ç†å·¥å…·")
    logger.info("="*60)
    logger.info(f"æ¨¡å‹ç±»å‹: {args.model}")
    logger.info(f"è¾“å…¥æ•°æ®: {args.data}")
    logger.info(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
    if args.features:
        logger.info(f"ä½¿ç”¨ç‰¹å¾: {len(args.features)} ä¸ªç‰¹å¾")
    logger.info("="*60)

    try:
        # åˆ›å»ºé…ç½®
        config = MLConfig()

        # åˆå§‹åŒ–æ¨ç†å·¥å…·
        inference = ModelInference(config)

        # åŠ è½½æ¨¡å‹
        logger.info(f"æ­£åœ¨åŠ è½½ {args.model} æ¨¡å‹...")
        inference.load_models(args.model, num_folds=args.num_folds)
        logger.info(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")

        # æ‰§è¡Œæ¨ç†
        logger.info("å¼€å§‹æ¨ç†...")
        results = inference.inference_from_csv(
            model_name=args.model,
            csv_path=args.data,
            feature_columns=args.features,
            voting=args.voting,
            evaluate=args.evaluate
        )

        # ä¿å­˜ç»“æœ
        results.to_csv(args.output, index=False)
        logger.info(f"âœ“ æ¨ç†ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
        logger.info(f"ç»“æœæ•°æ®å½¢çŠ¶: {results.shape}")

        # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
        if args.show_summary and 'predicted_label' in results.columns:
            logger.info("\né¢„æµ‹ç»“æœæ±‡æ€»:")
            pred_summary = results['predicted_label'].value_counts()
            for label, count in pred_summary.items():
                percentage = (count / len(results)) * 100
                logger.info(f"  ç±»åˆ« {label}: {count} ä¸ªæ ·æœ¬ ({percentage:.1f}%)")

        # æ˜¾ç¤ºå‡†ç¡®ç‡ä¿¡æ¯ï¼ˆå¦‚æœå·²è®¡ç®—ï¼‰
        if args.evaluate and 'accuracy_score' in results.columns:
            overall_accuracy = results['accuracy_score'].iloc[0]  # æ‰€æœ‰è¡Œéƒ½æœ‰ç›¸åŒçš„å‡†ç¡®ç‡å€¼
            logger.info(f"\nğŸ“Š æ•´ä½“å‡†ç¡®ç‡: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)")

        # æ˜¾ç¤ºå‰å‡ æ¡ç»“æœ
        if len(results) > 0:
            logger.info("\nå‰5æ¡é¢„æµ‹ç»“æœ:")
            display_cols = ['predicted_label']
            if args.features and len(args.features) <= 3:
                display_cols = args.features + display_cols

            print(results[display_cols].head().to_string())

        logger.info("="*60)
        logger.info("æ¨ç†å®Œæˆï¼")
        logger.info("="*60)

    except FileNotFoundError as e:
        logger.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        logger.error("è¯·ç¡®ä¿æ¨¡å‹å·²è®­ç»ƒå¹¶ä¿å­˜åœ¨ ./models/ ç›®å½•ä¸‹")
        sys.exit(1)
    except Exception as e:
        logger.error(f"æ¨ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()