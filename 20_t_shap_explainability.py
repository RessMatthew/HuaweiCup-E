#!/usr/bin/env python3
"""
SHAPå¯è§£é‡Šæ€§åˆ†æè„šæœ¬
ç”¨äºå¯¹å››åˆ†ç±»XGBoostæ¨¡å‹è¿›è¡Œå¯è§£é‡Šæ€§åˆ†æ

ç”Ÿæˆå†…å®¹ï¼š
- åŠ›å›¾ï¼ˆè§£é‡Šå•æ¬¡é¢„æµ‹ï¼‰ï¼šå››ä¸ªç±»å„äº”å¼ 
- æ‘˜è¦å›¾ï¼ˆä»æ€»ä½“ä¸Šçœ‹ï¼Œå“ªäº›ç‰¹å¾æœ€é‡è¦ï¼‰ï¼šå››ä¸ªç±»å„ä¸€å¼ 
- å›¾ç‰‡ç”Ÿæˆåœ¨ ./out/SHAP ç›®å½•ä¸‹

ä½¿ç”¨æ–¹æ³•:
python 20_t_shap_explainability.py --model xgboost --data data/t_data_daan_aligned.csv --segments_per_sample 124
"""

import sys
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import logging
from pathlib import Path
import argparse

# æ·»åŠ mlç›®å½•åˆ°è·¯å¾„
sys.path.append('ml')

from model_inference import ModelInference
from ml_config import MLConfig

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SHAPExplainability:
    """SHAPå¯è§£é‡Šæ€§åˆ†æç±»"""

    def __init__(self, config: MLConfig):
        self.config = config
        self.inference = ModelInference(config)
        self.output_dir = Path("./out/SHAP")
        self.shap_values = None
        self.explainer = None
        self.X_sample = None

        # é…è‰²æ–¹æ¡ˆ (85%é€æ˜åº¦)
        self.color_scheme = {
            'primary': '#237B9F',      # ä¸»è‰²
            'secondary': '#71BFB2',    # æ¬¡è¦è‰²
            'accent1': '#AD0B08',      # å¼ºè°ƒè‰²1
            'accent2': '#EC817E',      # å¼ºè°ƒè‰²2
            'accent3': '#FEE066',      # å¼ºè°ƒè‰²3
            'alpha': 0.85
        }

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®matplotlibæ ·å¼
        plt.style.use('default')
        sns.set_palette([
            self.color_scheme['primary'],
            self.color_scheme['secondary'],
            self.color_scheme['accent1'],
            self.color_scheme['accent2'],
            self.color_scheme['accent3']
        ])

    def load_data_and_model(self, model_name: str, csv_path: str, segments_per_sample: int = 124):
        """åŠ è½½æ•°æ®å’Œæ¨¡å‹"""
        logger.info("="*60)
        logger.info("åŠ è½½æ•°æ®å’Œæ¨¡å‹")
        logger.info("="*60)

        # åŠ è½½æ•°æ®
        df = pd.read_csv(csv_path)
        logger.info(f"æ•°æ®æ–‡ä»¶: {csv_path}")
        logger.info(f"æ•°æ®å½¢çŠ¶: {df.shape}")

        # ä½¿ç”¨æ‰€æœ‰ç‰¹å¾åˆ—ï¼ˆå‡è®¾æ²¡æœ‰ç›®æ ‡åˆ—ï¼‰
        feature_columns = df.columns.tolist()
        X = df[feature_columns].values

        logger.info(f"ç‰¹å¾æ•°é‡: {len(feature_columns)}")
        logger.info(f"ç‰¹å¾åç§°: {feature_columns[:10]}...")  # æ˜¾ç¤ºå‰10ä¸ªç‰¹å¾

        # åŠ è½½æ¨¡å‹
        self.inference.load_models(model_name)
        logger.info(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ: {model_name}")

        return X, feature_columns

    def prepare_sample_data(self, X: np.ndarray, segments_per_sample: int = 124):
        """å‡†å¤‡æ ·æœ¬æ•°æ®ç”¨äºSHAPåˆ†æ"""
        logger.info("å‡†å¤‡æ ·æœ¬æ•°æ®...")

        total_samples = len(X) // segments_per_sample
        logger.info(f"æ€»æ ·æœ¬æ•°: {total_samples}")

        # ä»æ¯ä¸ªæ ·æœ¬ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªæ®µä½œä¸ºä»£è¡¨
        sample_indices = []
        for i in range(total_samples):
            start_idx = i * segments_per_sample
            end_idx = start_idx + segments_per_sample
            # éšæœºé€‰æ‹©è¯¥æ ·æœ¬çš„ä¸€ä¸ªæ®µ
            random_segment_idx = np.random.choice(range(start_idx, end_idx))
            sample_indices.append(random_segment_idx)

        self.X_sample = X[sample_indices]
        logger.info(f"æ ·æœ¬æ•°æ®å½¢çŠ¶: {self.X_sample.shape}")

        return sample_indices

    def create_explainer(self, X: np.ndarray, feature_names: list):
        """åˆ›å»ºSHAPè§£é‡Šå™¨"""
        logger.info("åˆ›å»ºSHAPè§£é‡Šå™¨...")

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹åˆ›å»ºè§£é‡Šå™¨
        model = self.inference.loaded_models[self.inference.model_type][0]

        # åˆ›å»ºTreeExplainerï¼ˆé€‚ç”¨äºXGBoostï¼‰
        self.explainer = shap.TreeExplainer(model)

        # è®¡ç®—SHAPå€¼
        logger.info("è®¡ç®—SHAPå€¼...")
        self.shap_values = self.explainer.shap_values(X)

        logger.info(f"SHAPå€¼å½¢çŠ¶: {np.array(self.shap_values).shape}")

        return self.shap_values

    def plot_force_plots(self, class_labels: list, feature_names: list, num_samples_per_class: int = 5):
        """ç”ŸæˆåŠ›å›¾ - æ¯ä¸ªç±»åˆ«5ä¸ªæ ·æœ¬ (è‡ªå®šä¹‰å®ç°æ¨¡æ‹ŸåŠ›å›¾)"""
        logger.info("="*60)
        logger.info("ç”ŸæˆåŠ›å›¾ (æ¯ä¸ªç±»åˆ«5ä¸ªæ ·æœ¬)")
        logger.info("="*60)

        if self.shap_values is None or self.X_sample is None:
            raise ValueError("è¯·å…ˆè®¡ç®—SHAPå€¼")

        # è·å–é¢„æµ‹ç»“æœ
        predictions = self.inference.predict_ensemble(self.X_sample)

        for class_label in class_labels:
            logger.info(f"ç”Ÿæˆç±»åˆ« {class_label} çš„åŠ›å›¾...")

            # æ‰¾åˆ°è¯¥ç±»åˆ«å¯¹åº”çš„æ ·æœ¬ç´¢å¼•
            class_indices = np.where(predictions == class_label)[0]

            if len(class_indices) == 0:
                logger.warning(f"ç±»åˆ« {class_label} æ²¡æœ‰æ‰¾åˆ°æ ·æœ¬")
                continue

            # å¦‚æœæ ·æœ¬æ•°é‡ä¸è¶³ï¼Œé€‰æ‹©æ‰€æœ‰å¯ç”¨æ ·æœ¬
            selected_indices = class_indices[:min(num_samples_per_class, len(class_indices))]

            for i, sample_idx in enumerate(selected_indices):
                try:
                    # ç”Ÿæˆè‡ªå®šä¹‰åŠ›å›¾ - æ¨¡æ‹ŸSHAPåŠ›å›¾çš„è§†è§‰æ•ˆæœ
                    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 6),
                                                  gridspec_kw={'height_ratios': [3, 1]})

                    # å¯¹äºå¤šåˆ†ç±»é—®é¢˜
                    if isinstance(self.shap_values, list):
                        # è·å–è¯¥ç±»åˆ«çš„SHAPå€¼å’ŒåŸºçº¿å€¼
                        base_value = self.explainer.expected_value[class_label]
                        shap_values_single = self.shap_values[class_label][sample_idx]
                        features_single = self.X_sample[sample_idx]

                        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                        shap_values_single = np.array(shap_values_single).astype(float)
                        features_single = np.array(features_single).astype(float)
                    else:
                        # äºŒåˆ†ç±»é—®é¢˜
                        base_value = self.explainer.expected_value
                        shap_values_single = np.array(self.shap_values[sample_idx]).astype(float)
                        features_single = np.array(self.X_sample[sample_idx]).astype(float)

                    # å…³é”®ï¼šSHAPå€¼å½¢çŠ¶åº”è¯¥æ˜¯ (ç‰¹å¾æ•°,) è€Œä¸æ˜¯ (ç‰¹å¾æ•°, ç±»åˆ«æ•°)
                    # å¦‚æœSHAPå€¼æ˜¯å¤šç»´çš„ï¼Œéœ€è¦æ­£ç¡®å¤„ç†
                    if len(shap_values_single.shape) == 2 and shap_values_single.shape[1] == len(feature_names):
                        # å½¢çŠ¶ä¸º (ç±»åˆ«æ•°, ç‰¹å¾æ•°)ï¼Œéœ€è¦é€‰æ‹©å¯¹åº”ç±»åˆ«çš„SHAPå€¼
                        shap_values_single = shap_values_single[class_label] if shap_values_single.shape[0] > class_label else shap_values_single[0]
                    elif len(shap_values_single.shape) == 2 and shap_values_single.shape[0] == len(feature_names):
                        # å½¢çŠ¶ä¸º (ç‰¹å¾æ•°, ç±»åˆ«æ•°)ï¼Œç›´æ¥ä½¿ç”¨
                        shap_values_single = shap_values_single.ravel()[:len(feature_names)]

                    # è®¡ç®—é¢„æµ‹å€¼
                    if isinstance(base_value, (list, np.ndarray)):
                        prediction_value = float(base_value[0]) + np.sum(shap_values_single)
                    else:
                        prediction_value = float(base_value) + np.sum(shap_values_single)

                    # ç¡®ä¿SHAPå€¼æ˜¯1Dæ•°ç»„ä¸”é•¿åº¦åŒ¹é…
                    if len(shap_values_single) != len(feature_names):
                        logger.warning(f"SHAPå€¼æ•°é‡ ({len(shap_values_single)}) ä¸ç‰¹å¾åç§°æ•°é‡ ({len(feature_names)}) ä¸åŒ¹é…ï¼Œä½¿ç”¨å®é™…ç‰¹å¾æ•°é‡")
                        # æˆªæ–­æˆ–å¡«å……åˆ°åŒ¹é…çš„é•¿åº¦
                        if len(shap_values_single) > len(feature_names):
                            shap_values_single = shap_values_single[:len(feature_names)]
                        else:
                            # å¦‚æœSHAPå€¼è¾ƒå°‘ï¼Œåªä½¿ç”¨å¯¹åº”çš„ç‰¹å¾
                            feature_names = feature_names[:len(shap_values_single)]

                    abs_shap = np.abs(shap_values_single)

                    # åªæ˜¾ç¤ºå®é™…å­˜åœ¨çš„ç‰¹å¾
                    num_features = len(feature_names)

                    # æŒ‰é‡è¦æ€§æ’åº
                    top_indices = np.argsort(abs_shap)[-num_features:]

                    # ç›´æ¥ä½¿ç”¨ï¼Œå› ä¸ºå·²ç»ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
                    top_shap = shap_values_single[top_indices]
                    top_features = [feature_names[idx] for idx in top_indices]

                    # ä¸ŠåŠéƒ¨åˆ†ï¼šç‰¹å¾è´¡çŒ®æ¡å½¢å›¾ï¼ˆæ¨¡æ‹ŸåŠ›å›¾çš„ä¸»ä½“ï¼‰
                    colors = []
                    for x in np.array(top_shap).flat:
                        if x > 0:
                            colors.append(self.color_scheme['primary'])
                        else:
                            colors.append(self.color_scheme['accent1'])

                    bars = ax1.barh(range(len(top_shap)), top_shap,
                                   color=colors, alpha=self.color_scheme['alpha'])

                    ax1.set_yticks(range(len(top_features)))
                    ax1.set_yticklabels(top_features, fontsize=10)
                    ax1.set_xlabel('SHAP Value (Feature Contribution)', fontsize=12, color=self.color_scheme['primary'])
                    ax1.set_title(f'SHAP Force Plot - Class {class_label} Sample {i+1}',
                                 fontsize=14, color=self.color_scheme['primary'], pad=20)

                    # æ·»åŠ å‚ç›´çº¿è¡¨ç¤º0ç‚¹
                    ax1.axvline(x=0, color='black', linestyle='-', alpha=0.5, linewidth=2)

                    # æ·»åŠ ç½‘æ ¼
                    ax1.grid(axis='x', alpha=0.3, color=self.color_scheme['secondary'])

                    # è®¾ç½®xè½´èŒƒå›´ä»¥æ›´å¥½åœ°æ˜¾ç¤º
                    max_val = np.max(np.abs(top_shap))
                    ax1.set_xlim(-max_val * 1.1, max_val * 1.1)

                    # ä¸‹åŠéƒ¨åˆ†ï¼šåŸºçº¿å€¼å’Œé¢„æµ‹å€¼ï¼ˆæ¨¡æ‹ŸåŠ›å›¾çš„åº•éƒ¨åŒºåŸŸï¼‰
                    ax2.axis('off')

                    # åˆ›å»ºåŸºçº¿å’Œé¢„æµ‹çš„è§†è§‰æ•ˆæœ
                    try:
                        base_val = float(base_value[0]) if isinstance(base_value, (list, np.ndarray)) else float(base_value)
                        base_text = f'Base Value: {base_val:.3f}'
                    except:
                        base_text = f'Base Value: {base_value}'
                    pred_text = f'Output Value: {prediction_value:.3f}'

                    # ç»˜åˆ¶åŸºçº¿å€¼
                    ax2.text(0.1, 0.7, base_text, fontsize=12, color=self.color_scheme['primary'],
                            transform=ax2.transAxes, ha='left', va='center',
                            bbox=dict(boxstyle="round,pad=0.3", facecolor=self.color_scheme['secondary'], alpha=0.3))

                    # ç»˜åˆ¶é¢„æµ‹å€¼
                    ax2.text(0.9, 0.7, pred_text, fontsize=12, color=self.color_scheme['accent1'],
                            transform=ax2.transAxes, ha='right', va='center',
                            bbox=dict(boxstyle="round,pad=0.3", facecolor=self.color_scheme['accent2'], alpha=0.3))

                    # æ·»åŠ ç®­å¤´è¡¨ç¤ºä»åŸºçº¿åˆ°é¢„æµ‹çš„è½¬æ¢
                    ax2.annotate('', xy=(0.85, 0.7), xytext=(0.15, 0.7),
                                arrowprops=dict(arrowstyle='->', lw=2, color=self.color_scheme['primary']))

                    # æ·»åŠ å›¾ä¾‹
                    from matplotlib.patches import Patch
                    legend_elements = [
                        Patch(facecolor=self.color_scheme['primary'], alpha=self.color_scheme['alpha'],
                             label='Positive Impact (Increases Prediction)'),
                        Patch(facecolor=self.color_scheme['accent1'], alpha=self.color_scheme['alpha'],
                             label='Negative Impact (Decreases Prediction)')
                    ]
                    ax1.legend(handles=legend_elements, loc='lower right', fontsize=10)

                    # è°ƒæ•´å¸ƒå±€
                    plt.tight_layout()

                    # ä¿å­˜å›¾ç‰‡
                    output_path = self.output_dir / f'forceplot_class_{class_label}_sample_{i+1}.png'
                    plt.savefig(output_path, dpi=300, bbox_inches='tight',
                               facecolor='white', edgecolor='none')
                    plt.close()

                    logger.info(f"âœ“ åŠ›å›¾å·²ä¿å­˜: {output_path}")

                except Exception as e:
                    logger.error(f"ç”ŸæˆåŠ›å›¾å¤±è´¥ (ç±»åˆ« {class_label}, æ ·æœ¬ {i+1}): {e}")
                    import traceback
                    traceback.print_exc()
                    plt.close()
                    continue

    def plot_summary_plots(self, feature_names: list, class_labels: list):
        """ç”Ÿæˆæ‘˜è¦å›¾ - æ¯ä¸ªç±»åˆ«ä¸€å¼ """
        logger.info("="*60)
        logger.info("ç”Ÿæˆæ‘˜è¦å›¾ (æ¯ä¸ªç±»åˆ«ä¸€å¼ )")
        logger.info("="*60)

        if self.shap_values is None:
            raise ValueError("è¯·å…ˆè®¡ç®—SHAPå€¼")

        for class_label in class_labels:
            logger.info(f"ç”Ÿæˆç±»åˆ« {class_label} çš„æ‘˜è¦å›¾...")

            try:
                plt.figure(figsize=(12, 8))

                # å¯¹äºå¤šåˆ†ç±»é—®é¢˜
                if isinstance(self.shap_values, list):
                    # ä½¿ç”¨è¯¥ç±»åˆ«çš„SHAPå€¼ç”Ÿæˆæ‘˜è¦å›¾
                    shap.summary_plot(
                        self.shap_values[class_label],
                        self.X_sample,
                        feature_names=feature_names,
                        show=False,
                        plot_size=(12, 8),
                        color=self.color_scheme['primary']
                    )
                else:
                    # äºŒåˆ†ç±»é—®é¢˜
                    shap.summary_plot(
                        self.shap_values,
                        self.X_sample,
                        feature_names=feature_names,
                        show=False,
                        plot_size=(12, 8),
                        color=self.color_scheme['primary']
                    )

                # è‡ªå®šä¹‰æ ·å¼ - ä½¿ç”¨è‹±æ–‡æ ‡é¢˜é¿å…å­—ä½“é—®é¢˜
                plt.title(f'SHAP Summary Plot - Class {class_label}',
                         fontsize=16,
                         color=self.color_scheme['primary'],
                         pad=20)

                # è®¾ç½®é¢œè‰²é€æ˜åº¦
                for collection in plt.gca().collections:
                    if hasattr(collection, 'set_alpha'):
                        collection.set_alpha(self.color_scheme['alpha'])

                # ä¿å­˜å›¾ç‰‡
                output_path = self.output_dir / f'summary_class_{class_label}.png'
                plt.tight_layout()
                plt.savefig(output_path, dpi=300, bbox_inches='tight',
                           facecolor='white', edgecolor='none')
                plt.close()

                logger.info(f"âœ“ å·²ä¿å­˜: {output_path}")

            except Exception as e:
                logger.error(f"ç”Ÿæˆæ‘˜è¦å›¾å¤±è´¥ (ç±»åˆ« {class_label}): {e}")
                plt.close()
                continue

    def plot_overall_summary(self, feature_names: list):
        """ç”Ÿæˆæ€»ä½“æ‘˜è¦å›¾"""
        logger.info("ç”Ÿæˆæ€»ä½“æ‘˜è¦å›¾...")

        try:
            plt.figure(figsize=(14, 10))

            # è®¡ç®—å¹³å‡ç»å¯¹SHAPå€¼
            if isinstance(self.shap_values, list):
                # å¤šåˆ†ç±»ï¼šåˆå¹¶æ‰€æœ‰ç±»åˆ«çš„SHAPå€¼
                # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å¹³å‡ç»å¯¹SHAPå€¼ï¼ˆè·¨æ‰€æœ‰æ ·æœ¬å’Œç±»åˆ«ï¼‰
                all_shap_abs = [np.abs(shap_val) for shap_val in self.shap_values]
                # åœ¨ç±»åˆ«ç»´åº¦ä¸Šå¹³å‡ï¼Œç„¶ååœ¨æ ·æœ¬ç»´åº¦ä¸Šå¹³å‡
                feature_importance = np.mean([np.mean(class_shap, axis=0) for class_shap in all_shap_abs], axis=0)
            else:
                # äºŒåˆ†ç±»
                feature_importance = np.mean(np.abs(self.shap_values), axis=0)

            # ç¡®ä¿feature_importanceæ˜¯ä¸€ç»´æ•°ç»„å¹¶ä¸ç‰¹å¾æ•°é‡åŒ¹é…
            if feature_importance.ndim > 1:
                feature_importance = feature_importance.ravel()

            # ç¡®ä¿é•¿åº¦åŒ¹é…
            if len(feature_importance) != len(feature_names):
                logger.warning(f"Feature importance length ({len(feature_importance)}) != feature names length ({len(feature_names)})")
                # è°ƒæ•´é•¿åº¦
                min_len = min(len(feature_importance), len(feature_names))
                feature_importance = feature_importance[:min_len]
                feature_names = feature_names[:min_len]

            # åˆ›å»ºæ¡å½¢å›¾
            feature_df = pd.DataFrame({
                'feature': feature_names,
                'importance': feature_importance
            }).sort_values('importance', ascending=True)

            # ç»˜åˆ¶æ°´å¹³æ¡å½¢å›¾
            plt.barh(range(len(feature_df)), feature_df['importance'],
                    color=self.color_scheme['primary'], alpha=self.color_scheme['alpha'])

            plt.yticks(range(len(feature_df)), feature_df['feature'])
            plt.xlabel('Mean Absolute SHAP Value', fontsize=12)
            plt.ylabel('Features', fontsize=12)
            plt.title('Feature Importance Ranking (Based on SHAP Values)', fontsize=16,
                     color=self.color_scheme['primary'], pad=20)

            # æ·»åŠ ç½‘æ ¼
            plt.grid(axis='x', alpha=0.3, color=self.color_scheme['secondary'])

            # ä¿å­˜å›¾ç‰‡
            output_path = self.output_dir / 'overall_feature_importance.png'
            plt.tight_layout()
            plt.savefig(output_path, dpi=300, bbox_inches='tight',
                       facecolor='white', edgecolor='none')
            plt.close()

            logger.info(f"âœ“ Overall summary plot saved: {output_path}")

            # ä¿å­˜ç‰¹å¾é‡è¦æ€§æ•°æ®
            importance_csv_path = self.output_dir / 'feature_importance.csv'
            feature_df.to_csv(importance_csv_path, index=False)
            logger.info(f"âœ“ Feature importance data saved: {importance_csv_path}")

        except Exception as e:
            logger.error(f"Failed to generate overall summary plot: {e}")
            import traceback
            traceback.print_exc()
            plt.close()

    def run_analysis(self, model_name: str, csv_path: str, segments_per_sample: int = 124):
        """è¿è¡Œå®Œæ•´çš„SHAPåˆ†æ"""
        logger.info("="*60)
        logger.info("å¼€å§‹SHAPå¯è§£é‡Šæ€§åˆ†æ")
        logger.info("="*60)

        try:
            # 1. åŠ è½½æ•°æ®å’Œæ¨¡å‹
            X, feature_names = self.load_data_and_model(model_name, csv_path, segments_per_sample)

            # 2. å‡†å¤‡æ ·æœ¬æ•°æ®
            sample_indices = self.prepare_sample_data(X, segments_per_sample)

            # 3. åˆ›å»ºè§£é‡Šå™¨å¹¶è®¡ç®—SHAPå€¼
            self.create_explainer(self.X_sample, feature_names)

            # 4. è·å–ç±»åˆ«ä¿¡æ¯ï¼ˆåŸºäºé¢„æµ‹ç»“æœï¼‰
            predictions = self.inference.predict_ensemble(self.X_sample)
            unique_classes = np.unique(predictions)
            logger.info(f"æ£€æµ‹åˆ°çš„ç±»åˆ«: {unique_classes}")

            # 5. ç”ŸæˆåŠ›å›¾
            self.plot_force_plots(unique_classes, feature_names, num_samples_per_class=5)

            # 6. ç”Ÿæˆæ‘˜è¦å›¾
            self.plot_summary_plots(feature_names, unique_classes)

            # 7. ç”Ÿæˆæ€»ä½“æ‘˜è¦å›¾
            self.plot_overall_summary(feature_names)

            logger.info("="*60)
            logger.info("âœ“ SHAPåˆ†æå®Œæˆï¼")
            logger.info(f"âœ“ ç»“æœä¿å­˜åœ¨: {self.output_dir}")
            logger.info("="*60)

        except Exception as e:
            logger.error(f"SHAPåˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='SHAPå¯è§£é‡Šæ€§åˆ†æå·¥å…· - å››åˆ†ç±»æ¨¡å‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¯¹XGBoostæ¨¡å‹è¿›è¡ŒSHAPåˆ†æ
  python 16_t_shap_explainability.py --model xgboost --data data/t_data_daan_aligned.csv --segments_per_sample 124

  # ä½¿ç”¨é»˜è®¤å‚æ•°
  python 16_t_shap_explainability.py --model xgboost --data data/t_data_daan_aligned.csv
        """
    )

    parser.add_argument('--model', type=str, required=True,
                       choices=['xgboost', 'random_forest', 'knn', 'svm', 'decision_tree',
                               'adaboost', 'extra_trees', 'gradient_boosting', 'bagging_ensemble'],
                       help='è¦åˆ†æçš„æ¨¡å‹ç±»å‹')

    parser.add_argument('--data', type=str, required=True,
                       help='è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„ (å¦‚: data/t_data_daan_aligned.csv)')

    parser.add_argument('--segments_per_sample', type=int, default=124,
                       help='æ¯ä¸ªæ ·æœ¬çš„åˆ†æ®µæ•°é‡ (é»˜è®¤: 124)')

    parser.add_argument('--output_dir', type=str, default='./out/SHAP',
                       help='è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: ./out/SHAP)')

    args = parser.parse_args()

    # è®¾ç½®é»˜è®¤è¾“å‡ºæ–‡ä»¶å
    logger.info("="*60)
    logger.info("SHAPå¯è§£é‡Šæ€§åˆ†æå·¥å…·")
    logger.info("="*60)
    logger.info(f"æ¨¡å‹ç±»å‹: {args.model}")
    logger.info(f"è¾“å…¥æ•°æ®: {args.data}")
    logger.info(f"åˆ†æ®µæ•°é‡: {args.segments_per_sample}")
    logger.info(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    logger.info("="*60)

    try:
        # åˆ›å»ºé…ç½®
        config = MLConfig()

        # åˆå§‹åŒ–SHAPåˆ†æå™¨
        shap_analyzer = SHAPExplainability(config)

        # ä¿®æ”¹è¾“å‡ºç›®å½•ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.output_dir != './out/SHAP':
            shap_analyzer.output_dir = Path(args.output_dir)
            shap_analyzer.output_dir.mkdir(parents=True, exist_ok=True)

        # è¿è¡Œåˆ†æ
        shap_analyzer.run_analysis(
            model_name=args.model,
            csv_path=args.data,
            segments_per_sample=args.segments_per_sample
        )

        logger.info("\nğŸ‰ åˆ†æå®Œæˆï¼ç”Ÿæˆçš„æ–‡ä»¶åŒ…æ‹¬:")
        logger.info("- åŠ›å›¾: forceplot_class_*_sample_*.png")
        logger.info("- æ‘˜è¦å›¾: summary_class_*.png")
        logger.info("- æ€»ä½“ç‰¹å¾é‡è¦æ€§: overall_feature_importance.png")
        logger.info("- ç‰¹å¾é‡è¦æ€§æ•°æ®: feature_importance.csv")

    except FileNotFoundError as e:
        logger.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        logger.error("è¯·ç¡®ä¿æ¨¡å‹å·²è®­ç»ƒå¹¶ä¿å­˜åœ¨ ./models/ ç›®å½•ä¸‹")
        sys.exit(1)
    except Exception as e:
        logger.error(f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()